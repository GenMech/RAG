# Retrieval-Augmented Generation (RAG) 
If is a powerful and popular technique that applies specialized knowledge to large language models (LLMs). However, traditional RAG methods tend to have increasingly long prompts, sometimes exceeding 40k, which can result in high financial and latency costs. Moreover, the decreased information density within the prompts can lead to performance degradation in LLMs, such as the "lost in the middle" issue.

# Tools Used
- Pinecone
- GroqCloud
- Cohere
